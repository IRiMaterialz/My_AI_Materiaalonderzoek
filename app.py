import os
import json
import streamlit as st
import pandas as pd
import openai
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

# âœ… Zorg ervoor dat alle benodigde pakketten zijn geÃ¯nstalleerd
os.system("pip install -r requirements.txt")

# âœ… Streamlit UI Instellingen
st.set_page_config(page_title="AI Ondersteund Materiaalonderzoek", layout="wide")
st.title("ğŸ”¬ AI Ondersteund Materiaalonderzoek")
st.write("Welkom bij je AI-gestuurde onderzoeksapp! ğŸš€")

# âœ… OpenAI API Sleutel invoeren
api_key = st.text_input("ğŸ”‘ Voer je OpenAI API sleutel in:", type="password")

# âœ… AI Model Kiezen
model = st.selectbox("ğŸ¤– Kies een AI-model:", ["gpt-3.5-turbo", "gpt-4"])

# âœ… Onderzoeksvraag invoeren
onderzoeksvraag = st.text_area("ğŸ“„ Voer je onderzoeksvraag in:")

# âœ… AI-gestuurd Literatuuronderzoek
if st.button("ğŸ” Zoek Literatuur"):
    if api_key and onderzoeksvraag:
        try:
            # âœ… Maak verbinding met OpenAI
            llm = ChatOpenAI(model=model, temperature=0.3, openai_api_key=api_key)

            # âœ… Maak de prompt voor AI
            prompt = PromptTemplate(
                input_variables=["onderzoeksvraag"],
                template="Geef een overzicht van de meest relevante literatuur over {onderzoeksvraag}."
            )

            # âœ… Vraag OpenAI om een antwoord
            antwoord = llm.invoke(prompt.format(onderzoeksvraag=onderzoeksvraag))

            # âœ… Debug: toon de ruwe output
            st.subheader("ğŸ›  AI-Ruwe Output (Debug)")
            st.json(antwoord)  # Toont de volledige JSON-response voor debugging

            # âœ… Extract AI-content uit OpenAI JSON-output
            try:
                if isinstance(antwoord, str):
                    antwoord_dict = json.loads(antwoord)
                else:
                    antwoord_dict = antwoord  # Gebruik direct als het al een dictionary is

                # âœ… Controleer of het OpenAI-formaat klopt
                if isinstance(antwoord_dict, dict) and "choices" in antwoord_dict:
                    # âœ… Haal de daadwerkelijke AI-tekst eruit
                    ai_text = antwoord_dict["choices"][0]["message"]["content"]

                    st.subheader("ğŸ“š AI-Antwoord:")
                    st.write(ai_text)  # Toon alleen de AI-gegenereerde content
                else:
                    st.warning("âš  Geen geldig AI-antwoord ontvangen. Controleer de API-output.")

            except json.JSONDecodeError:
                st.error("âŒ Fout bij het verwerken van de AI-uitvoer. Probeer het opnieuw.")
            except Exception as e:
                st.error(f"âŒ Onverwachte fout: {e}")

        except Exception as e:
            st.error(f"âŒ Fout bij het aanroepen van OpenAI API: {e}")
    else:
        st.warning("âš  Voer zowel een API-sleutel als een onderzoeksvraag in!")

# âœ… Meetdata uploaden en analyseren
st.subheader("ğŸ“‚ Upload meetdata (CSV-formaat)")
uploaded_file = st.file_uploader("ğŸ“ Kies een CSV-bestand", type=["csv"])

if uploaded_file:
    try:
        metingen = pd.read_csv(uploaded_file)
        st.write("ğŸ“Š GeÃ¼ploade Meetdata:")
        st.dataframe(metingen)

        # âœ… Vergelijking met literatuurwaarden
        literatuur_waarden = {"gemiddelde": 0.10, "tolerantie": 0.02}
        metingen["afwijking"] = metingen["efflorescentie"] - literatuur_waarden["gemiddelde"]
        metingen["acceptabel"] = metingen["afwijking"].abs() <= literatuur_waarden["tolerantie"]

        st.subheader("ğŸ“Š Vergelijking met Literatuur:")
        st.dataframe(metingen)

    except Exception as e:
        st.error(f"âŒ Fout bij het verwerken van de meetdata: {e}")

# âœ… Automatisch een rapport genereren
if uploaded_file and st.button("ğŸ“„ Genereer Rapport"):
    try:
        rapport_prompt = PromptTemplate(
            input_variables=["metingen", "literatuur"],
            template="""
            Op basis van de uitgevoerde metingen en literatuurvergelijking zijn de volgende resultaten gevonden:

            - Gemeten efflorescentie: {metingen}
            - Vergelijking met literatuur: {literatuur}

            Op basis hiervan worden de volgende verbeteringen voorgesteld:
            """
        )

        llm = ChatOpenAI(model=model, temperature=0.3, openai_api_key=api_key)  # âœ… Zorg ervoor dat `llm` correct wordt aangemaakt

        rapport = llm.invoke(rapport_prompt.format(
            metingen=str(metingen),
            literatuur="Volgens studies is de gemiddelde efflorescentie 0.10 mg/cmÂ²."
        ))

        # âœ… Debugging: Toon de ruwe output
        st.subheader("ğŸ›  AI-Ruwe Output (Debug)")
        st.json(rapport)  # Toont de volledige JSON-response voor debugging

        # âœ… Extract AI-content uit OpenAI JSON-output
        try:
            if isinstance(rapport, str):
                rapport_dict = json.loads(rapport)
            else:
                rapport_dict = rapport

            if isinstance(rapport_dict, dict) and "choices" in rapport_dict:
                ai_text = rapport_dict["choices"][0]["message"]["content"]
                st.subheader("ğŸ“„ Gegenereerd Rapport")
                st.write(ai_text)
            else:
                st.warning("âš  Geen geldig AI-antwoord ontvangen. Controleer de API-output.")

        except json.JSONDecodeError:
            st.error("âŒ Fout bij het verwerken van de AI-uitvoer. Probeer het opnieuw.")
        except Exception as e:
            st.error(f"âŒ Onverwachte fout: {e}")

    except Exception as e:
        st.error(f"âŒ Fout bij het genereren van het rapport: {e}")
